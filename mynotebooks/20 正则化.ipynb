{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Overfitting\n",
    "   * More data\n",
    "   * Constraint model complexity\n",
    "        * <font face=\"黑体\" color=green size=3>shallow</font>\n",
    "        * <font face=\"黑体\" color=green size=3>regularization</font>\n",
    "   * Dropout\n",
    "   * Data argumentation\n",
    "   * Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization=weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1-regularization\n",
    "$$J(\\theta) = -\\frac {1}{m} \\sum_{i=1}^{m}[y_iln \\hat{y_i}+(1-y_i)ln(1-\\hat{y_i})]+ \\lambda \\sum_{i=1}^n \\left|{\\theta _i}\\right|$$\n",
    "#### L2-regularization\n",
    "$$J(W; X,y)+\\frac{1}{2} \\lambda \\cdot \\left||W\\right||^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2-regulation\n",
    "```python\n",
    "device = torch.device('cuda:0')\n",
    "net = MLP().to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.01)    # add L2-regulation\n",
    "criteon = nn.CrossEntropyLoss().to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1-regularization\n",
    "```python\n",
    "regularization_loss = 0\n",
    "for param in model.parameters():\n",
    "    regularization_loss += torch.sum(torch.abs(param))\n",
    "    \n",
    "classify_loss = criteon(logits, target)\n",
    "loss = classify_loss + 0.01 * regularization_loss    # lambda=0.01\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# momentum and learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tricks\n",
    "* momentum\n",
    "* learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### momentum在pytorch中的实现：\n",
    "```python\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam中已经有momentum。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate decay在pytorch中的实现："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scheme 1:  \n",
    "\n",
    "```python\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "for epoch in xange(args.start_epoch, args.epochs):\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "    result_avg, loss_val = validate(val_loader, model, criterion, epoch)\n",
    "    scheduler.step(loss_val)\n",
    "```\n",
    "\n",
    "sheme2:\n",
    "```python\n",
    "# Assuming optimizer uses lr = 0.05 for all groups\n",
    "# lr = 0.05     if epoch < 30\n",
    "# lr = 0.005     if 30 <= epoch < 60\n",
    "# lr = 0.0005    if 60 <= epoch < 90\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    scheduler.step()\n",
    "    train(...)\n",
    "    validate(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# early stop and dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tricks\n",
    "* Early stopping\n",
    "* Dropout\n",
    "* Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "<img src='./images/24.png' style=\"zoom:50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "<img src='./images/25.png' style=\"zoom:50%\">   \n",
    "<img src='./images/26.png' style=\"zoom:50%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "net_dropped = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784, 200)\n",
    "    torch.nn.Dropout(0.5)             # drop 50% of the neuron\n",
    "    torch.nn.ReLU()\n",
    "    torch.nn.Linear(200, 200)\n",
    "    torch.nn.Dropout(0.5)             # drop 50% of the neuron\n",
    "    torch.nn.ReLU()\n",
    "    torch.nn.Linear(200, 10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clarification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.Dropout(p=dropout_prob)   =1 断  \n",
    "tf.nn.dropout(keep_prob)        =1保持"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior between train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #train\n",
    "    net_dropped.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        ...\n",
    "    net_dropped.eval()          # 在validation的时候一定要取消dropout，这样可以提高结果。\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in best_loader:\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stochastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Deterministic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
